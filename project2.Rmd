---
title: "Project 2"
author: "Craig Lazarski"
date: "October 15, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries
```{r message=FALSE, warning=FALSE}
library("tidyverse")
library("GGally")
library("caret")
set.seed(1234)
```
Read in and subset the data
```{r message=FALSE}
news <- read_csv("OnlineNewsPopularity.csv")

business <- news %>% filter(data_channel_is_bus == 1)
lifestyle <- news %>% filter(data_channel_is_lifestyle == 1)
entertainment <- news %>% filter(data_channel_is_entertainment == 1)
socmed <- news %>% filter(data_channel_is_socmed == 1)
tech <- news %>% filter(data_channel_is_tech == 1)
world <- news %>% filter(data_channel_is_world == 1)

# The sum of these rows does not equal the total number of rows in news.

# Check if there are unclassified observations
other <- news %>% filter((data_channel_is_lifestyle + data_channel_is_entertainment + data_channel_is_lifestyle + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world) == 0)

# This accounts for all of the data. Life is good.
```
  
  Now that we had an excellent partitioning of the data.  By going to the website and reading the descriptions of the variables, we became interested to see if there was a time influence on the number of shares.  If an article was published on a week day versus a weekend, would it get more shares?  We thought so, with an intuition that people read more articles at work, and thus would be more likely to share articles that publish during the work week.  Let's see if we were on to something, shall we...  
    

Set the channel
```{r}
channel <- business
```

    
```{r message=FALSE, warning=FALSE}

channel <- channel %>% mutate(day = 
            if_else(weekday_is_monday == 1, 'Monday', 
            if_else( weekday_is_tuesday == 1, 'Tuesday',
            if_else(weekday_is_wednesday == 1 , 'Wednesday', 
            if_else( weekday_is_thursday == 1 ,  'Thursday' ,
            if_else(weekday_is_friday == 1, 'Friday',
            if_else(weekday_is_saturday == 1, 'Saturday', 'Sunday')))))))

channel$day <- factor(channel$day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
ggplot(data=channel, aes(x=day, y=shares)) +
  geom_col()

```    
This graph indicates which day has the most shares. A higher bar indicates more shares on that day.

```{r}
channel %>% group_by(day) %>% summarise(Total = sum(shares), mean = mean(shares), sd = sd(shares))

# Creating 'workweek' variable for modeling (Mon - Thurs VS Fri - Sun):

channel <- channel %>% mutate(workweek = 
            if_else(weekday_is_monday == 1 | weekday_is_tuesday == 1 |
                      weekday_is_wednesday == 1 |  weekday_is_thursday == 1, 'yes', 'no'))
```
The summary statistics indicate the total number of shares per day along with the average and stanard deviation. Days with the highest mean indicate more shares. A large standard deviation indicates high variability in the number of shares on that day.

Multi media

```{R}
# Make a new variable combining images and videos
channel <- channel %>% mutate(multimedia = num_imgs + num_videos)
channel <- channel %>% mutate(multimedia_category = 
                                  if_else(multimedia >= 30, "high",
                                  if_else(multimedia >= 20, "medium", 
                                  if_else(multimedia >= 10, "low", "very low"))))
channel$multimedia_category <- factor(channel$multimedia_category, levels = c("very low", "low", "medium", "high"))

ggplot(data = channel, aes(x= multimedia, y=shares)) +
  geom_point() +
  labs(x="Number of images and videos", y= "Shares", title = "Multimedia vs shares")
```
This graph displays the number of images and videos against the number of shares. A positive trend would indicate that more images and videos are associatied with more shares. A negative trend would indicate that more images and videos are associated with fewer shares.

```{r}
ggplot(data=channel, aes(x=multimedia_category, y=shares)) +
  geom_col()

```
This graph displays the number of videos and images in a shared article. A high bar indicates the category that was most prevalent. 

How long is the article

With today's shortened attention span, are shorter articles more likely to be shared?

```{r}
# First, what is the distribution of article length?
plot(channel$n_tokens_content)
results <- summary(news$n_tokens_content)

# Looks like the vast majority are 1000 words or less.  So we'll break them into quantiles: Blip, Short, Medium, Epic

channel <- channel %>% mutate(wordiness = if_else(n_tokens_content > results[[5]], 'Epic', if_else(n_tokens_content >results[[3]], 'Medium', if_else(n_tokens_content > results[[2]], 'Short', 'Blip'))))

channel$wordiness <- factor(channel$wordiness, levels = c("Blip", "Short", "Medium", "Epic"))

ggplot(data = channel, aes(x = wordiness, y=shares)) +
  geom_col() +
  labs(x="Wordiness", y= "Shares", title = "Wordiness vs shares")

# Summary of wordiness

channel %>% group_by(wordiness) %>% summarise(Total = sum(shares), mean = mean(shares), sd = sd(shares))


```
The category with the highest bar indicates which grouping of lengths was most shared for this category of articles.

The summary statistics show the total number of shares based on article length.  It also reports the average and the standard deviation.  If the standard deviation is high, then it says there's much more variation in the number of shares. 


How long is the title?
Is the title one word or a phrase?  Does length perhaps grab the readers attention to read it and then to pass it on...let's look and see.

```{r}
# First, what is the distribution of title length?
plot(channel$n_tokens_title)
results <- summary(news$n_tokens_title)
results
# Good God!  A title 23 words long???  Isn't that a sentence and not a title??? 
# Well, whatevers, grouping by quartiles:

channel <- channel %>% mutate(title_words = 
            if_else(n_tokens_title > results[[5]] , 'Long', 
                    if_else(n_tokens_title > results[[3]], 'Typical', 'Short')))

results[[5]]
channel$title_words <- factor(channel$title_words, 
                               levels = c("Short", "Typical", "Long"))

ggplot(data = channel, aes(x = title_words, y = shares)) + 
  geom_col() +
  labs(x="Title Length", y= "Shares", title = "Title Length vs shares")


```
The category with the highest bar indicates the length that is most shared.  

Would a long article have a long title?  Is there a relationship between article length and title length?  If so, there might be an issue of correlation.

```{r message=FALSE, warning=FALSE}

table(channel$wordiness, channel$title_words)

```

Is it a positive article, or negative?

This table compares the average number of shares based on positive and negative polarity of an article. If it is more positive than negative it is classified as positive, if not, negative. The summary statistics indicate the mean number of shares for articles classified as negative or positive and the standard deviation. A higher mean value would indicate more shares.

```{r}
channel <- channel %>% mutate(av_avg_neg_polarity = -1*avg_negative_polarity)
ggplot(data=channel, aes(x=av_avg_neg_polarity, y=avg_positive_polarity)) +
  geom_point() +
  stat_function(fun=function(x) x, size = 2, lty = 3 ,color = 'red')

```
This graph shows the relationship between the positive and negative polarity of an article. Values above the line y=x would indicate more positive and values below the line y=x indicate more negativity.


The graphs below the distribution of shares according to their positive and negative polarity rating. The peak of the distribution indicates what rating has the most shares.



```{r}
channel <- channel %>% mutate( sentiment = if_else(avg_positive_polarity > av_avg_neg_polarity, "positive", "negative"))

channel %>% group_by(sentiment) %>% summarise(mean = mean(shares), sd= sd(shares), sum = sum(shares), ratio = sum(shares))
summary(news$shares)

channel2 <- channel %>% subset(shares >= 2800) 

ggplot(data = channel2, aes(x=sentiment, y=shares)) +
  geom_col()
```
This graph took the 25% of articles with the most shares and display the shares based on their positivity or negativity. The higher bar will indicate what the most shared articles can be categorized as that sentiment.


Is the title subjective?  Do shares lean towards opinion over objectiveness?  We would venture yes!

```{r}
plot(channel$title_subjectivity)

head(channel$title_subjectivity)

# Looks like the data is a ranking 0 to 1, and is continuous.  Scatterplot time! :)

g2 <- ggplot(channel, aes(x = title_subjectivity, y = shares))
g2 + geom_point() 

```

   
```{r}
channel <- channel %>% mutate(subjectivity = if_else(title_subjectivity <=.3, "No Subjectivity", if_else(title_subjectivity <= .7, "Somewhat Subjective", "Very Subjective")))


#### ISSUE  ggplot(data=business2, aes(x=subjectivity, y=shares)) +   geom_col()

```
If a title had a subjectivity rating below 0.3 it was classified as Not subjective, between 0.3 and 0.7 as somewhat subjective, and over 0.7 very subjective. THe highest bar in any column would indicate that the most shared articles have a subjectivity of that bars rating.  A high bar in the very subjective column would indicate that the title subjectivity was hard to classify and may contribute to a higher missclassification rate.




A linear model is about fitting your mom ...
After I pee my rsqured is much lower. 

Splitting data into a training and test set (70/30):
```{r message=FALSE, warning=FALSE}

# seed was already set...

# indices to split on
# want 70% to train on
trainIndex <- createDataPartition(channel$shares, p = .7, list = FALSE)


# subsets of data
channelTrain <- channel[trainIndex, ]
channelTest <- channel[-trainIndex, ]


```
Linear Models

A linear model seeks to minimize the sum of the squared distances between the observed values and the predicted values. In this scenario the number of shares are the observed values. The predicted number of shares will be determined by the variables that are used in each model. Predicted values are found by inputting a value for each model variable and then applying the model coefficients to those inputs and summing the results. The coefficients associated with each model variable are the ones that minimized the squared distance between that prediction and the observed value. Adding more variables increases the complexity of the model but may also increase the predictive ability. Using terms that are transformations of the original variables (such as squaring) can add more flexibility to the model allowing for increased prediction ability. We can evaluate a model by examining measures such as the mean squared error which averages the distances between the predictions and observed values (we want this number to be small), the R-squared value which tells us how much of the variation is explained by the model variables (we want this number to be near 1), or residual plots which illuminate potentiall outlier values or influential points.

```{R}
# Linear model using all of the variables in our EDA

LM0 <- train(shares ~ n_tokens_title + n_tokens_content + num_imgs +num_videos + global_sentiment_polarity +is_weekend, data = channelTrain,
             method = "lm", 
             preProcess = c('center', 'scale'),
             trControl = trainControl(method = 'cv', number = 10))
LM0

pred1 <- predict(LM0, newdata = channelTest)
postResample(pred1, obs = channelTest$shares)


# Linear model involving only multimedia

LM1 <- train(shares ~ num_imgs + num_videos, data = channelTrain,
             method = "lm", 
             preProcess = c('center', 'scale'),
             trControl = trainControl(method = 'cv', number = 10))
LM1

pred1 <- predict(LM1, newdata = channelTest)
postResample(pred1, obs = channelTest$shares)


# Linear model based on when it was released Mon - Thur vs Fri - Sun

LM2 <- train(shares ~ workweek, data = channelTrain,
             method = "lm", 
             preProcess = c('center', 'scale'),
             trControl = trainControl(method = 'cv', number = 10))
LM2

pred2 <- predict(LM2, newdata = channelTest)
postResample(pred2, obs = channelTest$shares)

# Linear model based on length

LM3 <- train(shares ~ I(n_tokens_content)^2 + n_tokens_title, data = channelTrain,
             method = "lm", 
             preProcess = c('center', 'scale'),
             trControl = trainControl(method = 'cv', number = 10))
LM3

pred3 <- predict(LM3, newdata = channelTest)
postResample(pred3, obs = channelTest$shares)

```


Random forest model
```{r}
random_forest <- train(shares ~ n_tokens_title + n_tokens_content + num_imgs +num_videos + global_sentiment_polarity +is_weekend , data = channelTrain,
          method = "rf", 
          trControl = trainControl(method = "cv", number = 10),
          preProcess = c("center", "scale"),
          tuneGrid = data.frame(mtry = 1:6))

confusionMatrix(random_forest, newdata = channelTest)

```

```{r}
# Comparing models

```